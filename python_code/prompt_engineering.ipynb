{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0c3b26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install pinecone\n",
    "# !pip unstall openai\n",
    "# !pip install python-dotenv\n",
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ef71fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ec6b734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chatbot_response(client,model_name,messages,temperature=0):\n",
    "    input_messages = []\n",
    "    for message in messages:\n",
    "        input_messages.append({\"role\": message[\"role\"], \"content\": message[\"content\"]})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=input_messages,\n",
    "        temperature=temperature,\n",
    "        top_p=0.8,\n",
    "        max_tokens=2000,\n",
    "    ).choices[0].message.content\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4081d53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! It looks like it is working. I'm a large language model, and I'm here to help with any questions or tasks you have. What would you like to talk about or get assistance with today?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    base_url=\"https://api.groq.com/openai/v1\"\n",
    ")\n",
    "\n",
    "# Correct Groq Model ID\n",
    "model_name = \"llama-3.1-8b-instant\" \n",
    "\n",
    "# Test if it works\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello, is this working?\"}\n",
    "    ],\n",
    "    model=model_name,\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41ae661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "169aee36",
   "metadata": {},
   "source": [
    "# Get LLM response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ba7753a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Italy is Rome.\n"
     ]
    }
   ],
   "source": [
    "messages = [{'role':'user','content':\"What's the capital of Italy?\"}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d180eeb4",
   "metadata": {},
   "source": [
    "# Prompt engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a1db3e",
   "metadata": {},
   "source": [
    "## Structred output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d50ca843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "{\n",
      "    \"country\": \"Italy\",\n",
      "    \"capital\": \"Rome\"\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant that answer questions about capitals of countries.\n",
    "\n",
    "Your output should be in a structured json format exactly like the one bellow. You are not allowed to write anything other than the json object:\n",
    "[\n",
    "{\n",
    "    country: the country that you will get the capital of \n",
    "    capital: the capital of the country stated\n",
    "}\n",
    "]\n",
    "\"\"\"\n",
    "messages = [{'role':'system','content':system_prompt}]\n",
    "messages.append({'role':'user','content':\"What's the capital of Italy?\"})\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71161a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'country': 'Italy', 'capital': 'Rome'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response = json.loads(response)\n",
    "json_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e9575d",
   "metadata": {},
   "source": [
    "## input structuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "779e3f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "{\n",
      "    \"country\": \"Italy\",\n",
      "    \"capital\": \"Rome\"\n",
      "},\n",
      "{\n",
      "    \"country\": \"France\",\n",
      "    \"capital\": \"Paris\"\n",
      "},\n",
      "{\n",
      "    \"country\": \"Germany\",\n",
      "    \"capital\": \"Berlin\"\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "Get me the capitals of the following countries:\n",
    "```\n",
    "1. Italy\n",
    "2. France\n",
    "3. Germany\n",
    "``\n",
    "\"\"\"\n",
    "messages = [{'role':'system','content':system_prompt}]\n",
    "messages.append({'role':'user','content':user_prompt})\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79c2718a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'country': 'Italy', 'capital': 'Rome'},\n",
       " {'country': 'France', 'capital': 'Paris'},\n",
       " {'country': 'Germany', 'capital': 'Berlin'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response = json.loads(response)\n",
    "json_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ffda13",
   "metadata": {},
   "source": [
    "## Give the model time to think (Chain of thought)\n",
    "\n",
    "> https://arxiv.org/pdf/2205.11916"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0019ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eca28fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"result\": 4\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "Calculate the result of this equation: 1+3\n",
    "\n",
    "Your output should be in a structured json format exactly like the one bellow. You are not allowed to write anything other than the json object:\n",
    "{\n",
    "    result: The final number resulted from calculating the equation above\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "messages = [{'role':'user','content':user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0bd98b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4113098.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "259/2*8654+91072*33-12971"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f91f7373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"result\": 1434921119\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "Calculate the result of this equation: 259/2*8654+91072*33-12971\n",
    "\n",
    "Your output should be in a structured json format exactly like the one bellow. You are not allowed to write anything other than the json object:\n",
    "{\n",
    "    result: The final number resulted from calculating the equation above\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "messages = [{'role':'user','content':user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6243f166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2681649.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4113098.0 - 1431449.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58c5128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"\n",
    "Calculate the result of this equation: 259/2*8654+91072*33-12971\n",
    "\n",
    "Your output should be in a structured json format exactly like the one bellow. You are not allowed to write anything other than the json object:\n",
    "{\n",
    "    steps: This is where you solve the equation bit by bit following the BEDMAS order of operations. You need to show your work and calculate each step leading to final result. Feel free to write here in free text. \n",
    "    result: The final number resulted from calculating the equation above\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "messages = [{'role':'user','content':user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea4fb1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"steps\": \"First, we need to follow the BEDMAS order of operations. \n",
      "    1. Divide 259 by 2: 259/2 = 129.5\n",
      "    2. Multiply 129.5 by 8654: 129.5 * 8654 = 1121011\n",
      "    3. Multiply 91072 by 33: 91072 * 33 = 3005016\n",
      "    4. Add 1121011 and 3005016: 1121011 + 3005016 = 4126027\n",
      "    5. Subtract 12971 from 4126027: 4126027 - 12971 = 4113056\",\n",
      "    \"result\": 4113056\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66cf1d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4113098.0 - 4113056"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e6b197",
   "metadata": {},
   "source": [
    "# RAG - Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b93c481",
   "metadata": {},
   "source": [
    "#### Asking about a subject that the LLM does not know anything about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05eefa05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since I'm not aware of any official information about the iPhone 16, I'll provide you with some general information about the latest iPhone models and some rumored features that might be included in future iPhone models.\n",
      "\n",
      "However, I can tell you about the latest iPhone models, such as the iPhone 14 series, which includes:\n",
      "\n",
      "1. iPhone 14\n",
      "2. iPhone 14 Plus\n",
      "3. iPhone 14 Pro\n",
      "4. iPhone 14 Pro Max\n",
      "\n",
      "Some of the notable features of the iPhone 14 series include:\n",
      "\n",
      "1. Improved cameras with a new 48MP main camera on the Pro models\n",
      "2. Faster A16 Bionic chip\n",
      "3. Longer battery life\n",
      "4. New colors and designs\n",
      "5. Enhanced display with a higher refresh rate\n",
      "\n",
      "As for the iPhone 16, there's no official information available yet. However, based on rumors and leaks, here are some potential features that might be included:\n",
      "\n",
      "1. Improved cameras with a new periscope lens or a higher-resolution main camera\n",
      "2. Faster A17 Bionic chip or a new chip design\n",
      "3. Enhanced display with a higher refresh rate or a new OLED panel\n",
      "4. New colors and designs\n",
      "5. Improved battery life and charging capabilities\n",
      "6. Enhanced biometric security with a new fingerprint sensor or facial recognition system\n",
      "7. Integration with augmented reality (AR) and virtual reality (VR) technologies\n",
      "8. Improved water and dust resistance\n",
      "\n",
      "Please note that these are just rumors and speculations, and Apple has not officially announced any information about the iPhone 16.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "What's new in iphone 16?\n",
    "\"\"\"\n",
    "\n",
    "messages = [{'role':'user','content':user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e132c1",
   "metadata": {},
   "source": [
    "#### Giving Context to the unknown subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e753f57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iphone_16 = \"\"\"\n",
    "The iPhone 16 introduces several exciting updates, making it one of Apple's most advanced smartphones to date. It features a larger 6.1-inch display for the base model and a 6.7-inch screen for the iPhone 16 Plus, with thinner bezels and a more durable Ceramic Shield. The iPhone 16 Pro and Pro Max boast even larger displays, measuring 6.3 and 6.9 inches respectively, offering the thinnest bezels seen on any Apple product so far.\n",
    "\n",
    "Powered by the new A18 chip (A18 Pro for the Pro models), these phones deliver significant performance improvements, with enhanced neural engine capabilities, faster GPU for gaming, and machine learning tasks. The camera systems are also upgraded, with the base iPhone 16 sporting a dual-camera setup with a 48MP main sensor. The Pro models offer a 48MP Ultra Wide and 5x telephoto camera, enhanced by Apple’s \"Camera Control\" button for more flexible photography options.\n",
    "\n",
    "Apple also introduced advanced audio features like \"Audio Mix,\" which uses machine learning to separate background sounds from speech, allowing for more refined audio capture during video recording. Battery life has been extended, especially in the iPhone 16 Pro Max, which is claimed to have the longest-lasting battery of any iPhone \n",
    "9TO5MAC\n",
    "\n",
    "APPLEMAGAZINE\n",
    ".\n",
    "\n",
    "Additionally, Apple has switched to USB-C for faster charging and data transfer, and the Pro models now support up to 2x faster video encoding. The starting prices remain consistent with previous generations, with the iPhone 16 starting at $799, while the Pro models start at $999\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b31f5e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided information, the new features and updates in the iPhone 16 include:\n",
      "\n",
      "1. Larger display sizes:\n",
      "   - Base model: 6.1-inch display\n",
      "   - iPhone 16 Plus: 6.7-inch display\n",
      "   - iPhone 16 Pro: 6.3-inch display\n",
      "   - iPhone 16 Pro Max: 6.9-inch display\n",
      "\n",
      "2. Thinner bezels and a more durable Ceramic Shield\n",
      "\n",
      "3. Upgraded A18 chip (A18 Pro for Pro models) for improved performance, including:\n",
      "   - Enhanced neural engine capabilities\n",
      "   - Faster GPU for gaming\n",
      "   - Machine learning tasks\n",
      "\n",
      "4. Upgraded camera systems:\n",
      "   - Base iPhone 16: Dual-camera setup with a 48MP main sensor\n",
      "   - Pro models: 48MP Ultra Wide and 5x telephoto camera, with Apple's \"Camera Control\" button\n",
      "\n",
      "5. Advanced audio features:\n",
      "   - \"Audio Mix\" for refined audio capture during video recording\n",
      "\n",
      "6. Extended battery life, especially in the iPhone 16 Pro Max\n",
      "\n",
      "7. Switch to USB-C for faster charging and data transfer\n",
      "\n",
      "8. Support for up to 2x faster video encoding in Pro models\n",
      "\n",
      "9. Starting prices remain consistent with previous generations:\n",
      "   - iPhone 16: $799\n",
      "   - Pro models: $999\n"
     ]
    }
   ],
   "source": [
    "user_prompt = f\"\"\"\n",
    "{iphone_16}\n",
    "\n",
    "What's new in iphone 16?\n",
    "\"\"\"\n",
    "\n",
    "messages = [{'role':'user','content':user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902232f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "546d94c8",
   "metadata": {},
   "source": [
    "#### Automatically extract context data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86b0e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "samsung_s23 = \"\"\"\n",
    "The Samsung Galaxy S23 brings some incremental but notable upgrades to its predecessor, the Galaxy S22. It features the Snapdragon 8 Gen 2 processor, a powerful chip optimized for the S23 series, delivering enhanced performance, especially for gaming and multitasking. This chip ensures top-tier speed and efficiency across all models, from the base S23 to the larger S23+ and S23 Ultra​\n",
    "STUFF\n",
    "\n",
    "TECHRADAR\n",
    ".\n",
    "\n",
    "In terms of design, the S23's camera module has been streamlined by removing the raised metal contour around the cameras, creating a cleaner, sleeker look. It also sports the same 6.1-inch 120Hz AMOLED display, protected by tougher Gorilla Glass Victus 2, making it more resistant to scratches and drops​\n",
    "TECHRADAR\n",
    ".\n",
    "\n",
    "The S23 Ultra stands out with its 200MP main camera, offering impressive photo clarity, especially in low-light conditions. The selfie camera across the series has been updated to a 12MP sensor, resulting in sharper selfies. The Ultra model also includes productivity tools such as the S-Pen, which remains an essential feature for note-taking and creative tasks​\n",
    "STUFF\n",
    "\n",
    "TECHRADAR\n",
    ".\n",
    "\n",
    "Battery life is solid, with the S23 Ultra featuring a 5000mAh battery that lasts comfortably through a day of heavy use. However, charging speeds still lag behind some competitors, with 45W wired charging, which is slower than other brands offering up to 125W charging​\n",
    "STUFF\n",
    ".\n",
    "\n",
    "Overall, the Galaxy S23 series enhances performance, durability, and camera quality, making it a strong contender for users seeking a high-performance flagship.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "510711ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [iphone_16,samsung_s23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4b9efd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"What's new in iphone 16?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a12f389",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_client = OpenAI(\n",
    "        api_key=os.getenv(\"GROQ_API_KEY\"), \n",
    "        base_url=os.getenv(\"EMBEDDING_URL\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "88b3fd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(embedding_client,model_name,text_input):\n",
    "    output = embedding_client.embeddings.create(input = text_input,model=model_name)\n",
    "    \n",
    "    embedings = []\n",
    "    for embedding_object in output.data:\n",
    "        embedings.append(embedding_object.embedding)\n",
    "\n",
    "    return embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1661353-3c73-450d-9bd9-3574b3019a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using local machine for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9d06859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# --- EMBEDDING (LOCAL) ---\n",
    "# Initialize the local embedding model once outside the function\n",
    "local_embedding_model = SentenceTransformer('all-MiniLM-L6-v2') \n",
    "\n",
    "def get_embedding(model, text_input):\n",
    "    # This is now the local model's encode method\n",
    "    embedding_vector = model.encode(text_input).tolist()\n",
    "    return embedding_vector\n",
    "\n",
    "# --- LLM CLIENT (GROQ) ---\n",
    "# Initialize the Groq client for chat completions\n",
    "groq_client = OpenAI(\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    base_url=\"https://api.groq.com/openai/v1\"\n",
    ")\n",
    "groq_model = \"llama-3.1-8b-instant\"\n",
    "\n",
    "# --- EXAMPLE USAGE ---\n",
    "user_prompt = \"What are the new features of the iPhone 16?\"\n",
    "# Get embeddings using the local model object\n",
    "user_prompt_embeddings = get_embedding(local_embedding_model, user_prompt)\n",
    "# ... then use groq_client for the chat completion ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "feb94816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.027664165943861008,\n",
       " 0.06676303595304489,\n",
       " 0.0700257420539856,\n",
       " -0.05728081241250038,\n",
       " 0.02660966105759144,\n",
       " 0.011028705164790154,\n",
       " -0.03125479817390442,\n",
       " 0.0009957123547792435,\n",
       " -0.05516740307211876,\n",
       " 0.03669792041182518,\n",
       " 0.09570624679327011,\n",
       " 0.017850054427981377,\n",
       " -0.07627023756504059,\n",
       " 0.07319768518209457,\n",
       " 0.0464191660284996,\n",
       " -0.01411670632660389,\n",
       " 0.1106327548623085,\n",
       " -0.0326492078602314,\n",
       " -0.04606301710009575,\n",
       " -0.06636357307434082,\n",
       " -0.050390951335430145,\n",
       " -0.08455319702625275,\n",
       " 0.031811486929655075,\n",
       " 0.019057875499129295,\n",
       " 0.04801281541585922,\n",
       " 0.03449780121445656,\n",
       " -0.06899016350507736,\n",
       " -0.08249595761299133,\n",
       " -0.013204301707446575,\n",
       " -0.04358138516545296,\n",
       " 0.001232244074344635,\n",
       " 0.08278965950012207,\n",
       " 0.09351005405187607,\n",
       " 0.002129138680174947,\n",
       " -0.09207350760698318,\n",
       " -0.11647623032331467,\n",
       " 0.09164678305387497,\n",
       " 0.005110481753945351,\n",
       " 0.008118653669953346,\n",
       " -0.05999040976166725,\n",
       " -0.022250203415751457,\n",
       " -0.030106328427791595,\n",
       " -0.02097237855195999,\n",
       " 0.06972958892583847,\n",
       " 0.03418109938502312,\n",
       " -0.007412982638925314,\n",
       " 0.05772651731967926,\n",
       " 0.03489239513874054,\n",
       " 0.04290101304650307,\n",
       " -0.029522834345698357,\n",
       " 0.04329303652048111,\n",
       " -0.009565354324877262,\n",
       " -0.023335274308919907,\n",
       " 0.05937458947300911,\n",
       " 0.011667069047689438,\n",
       " -0.0406084880232811,\n",
       " -0.019999012351036072,\n",
       " 0.022938283160328865,\n",
       " 0.08116278797388077,\n",
       " 0.014760349877178669,\n",
       " 0.05587202310562134,\n",
       " -0.03477821126580238,\n",
       " -0.04179948568344116,\n",
       " 0.11342714726924896,\n",
       " -0.012839949689805508,\n",
       " -0.061604611575603485,\n",
       " -0.019671617075800896,\n",
       " -0.027785858139395714,\n",
       " 0.008461026474833488,\n",
       " 0.0027277828194200993,\n",
       " -0.011371674947440624,\n",
       " 0.0021925715263932943,\n",
       " -0.0063913376070559025,\n",
       " -0.08483795076608658,\n",
       " 0.03655443340539932,\n",
       " 0.026905668899416924,\n",
       " 0.013326267711818218,\n",
       " -0.005943056661635637,\n",
       " -0.029658809304237366,\n",
       " 0.0018201421480625868,\n",
       " 0.01615508832037449,\n",
       " -0.012955788522958755,\n",
       " 0.03544234484434128,\n",
       " -0.020172124728560448,\n",
       " 0.01713862270116806,\n",
       " 0.03940688073635101,\n",
       " -0.028894642367959023,\n",
       " -0.03541801869869232,\n",
       " -0.11314382404088974,\n",
       " -0.04094867408275604,\n",
       " 0.003164501627907157,\n",
       " 0.024682234972715378,\n",
       " -0.06754098832607269,\n",
       " -0.04558653384447098,\n",
       " -0.01989218220114708,\n",
       " -0.015667641535401344,\n",
       " 0.003532357281073928,\n",
       " -0.11953198909759521,\n",
       " -0.0026410941500216722,\n",
       " 0.0037532940041273832,\n",
       " 0.035388022661209106,\n",
       " 0.023980969563126564,\n",
       " 0.05449068546295166,\n",
       " 0.010869662277400494,\n",
       " 0.03980419039726257,\n",
       " -0.035393476486206055,\n",
       " 0.05091826990246773,\n",
       " -0.03815774619579315,\n",
       " -0.019658414646983147,\n",
       " 0.11731245368719101,\n",
       " 0.05494218319654465,\n",
       " -0.01897311396896839,\n",
       " -0.007000959478318691,\n",
       " -0.09242561459541321,\n",
       " 0.058044176548719406,\n",
       " -0.047432057559490204,\n",
       " 0.004258966073393822,\n",
       " 0.0841415748000145,\n",
       " 0.0832841694355011,\n",
       " 0.037736453115940094,\n",
       " -0.017557824030518532,\n",
       " -0.00653029466047883,\n",
       " -0.03185342252254486,\n",
       " -0.06425247341394424,\n",
       " -0.050866346806287766,\n",
       " 0.04030958190560341,\n",
       " -0.10522300004959106,\n",
       " -5.047227808307333e-33,\n",
       " 0.03783392906188965,\n",
       " 0.08062528818845749,\n",
       " -0.07980550080537796,\n",
       " -0.0012093952391296625,\n",
       " 0.013185864314436913,\n",
       " -0.061447445303201675,\n",
       " 0.0398678183555603,\n",
       " 0.03178606554865837,\n",
       " -0.02319491282105446,\n",
       " 0.0006687161512672901,\n",
       " -0.03312009200453758,\n",
       " 0.0011779816122725606,\n",
       " -0.07173694670200348,\n",
       " 0.006794678512960672,\n",
       " 0.1285446435213089,\n",
       " -0.0928201898932457,\n",
       " -0.10309069603681564,\n",
       " 0.00575646199285984,\n",
       " 0.05833819508552551,\n",
       " 0.031216835603117943,\n",
       " -0.014618685469031334,\n",
       " 0.023940173909068108,\n",
       " 0.003977207932621241,\n",
       " 0.08045491576194763,\n",
       " 0.06610501557588577,\n",
       " 0.025789154693484306,\n",
       " 0.04485968500375748,\n",
       " -0.013440734706819057,\n",
       " -0.03750821202993393,\n",
       " -0.008004769682884216,\n",
       " -0.08586844801902771,\n",
       " 0.10530287772417068,\n",
       " -0.03244340792298317,\n",
       " -0.04408971965312958,\n",
       " -0.04181286320090294,\n",
       " 0.028450598940253258,\n",
       " -0.0001162622356787324,\n",
       " -0.13739866018295288,\n",
       " 0.09302906692028046,\n",
       " -0.00028641708195209503,\n",
       " -0.04224465414881706,\n",
       " -0.02794710546731949,\n",
       " -0.10662525147199631,\n",
       " -0.0070709893479943275,\n",
       " 0.06883052736520767,\n",
       " 0.062027543783187866,\n",
       " -0.056848835200071335,\n",
       " -0.03472014144062996,\n",
       " 0.033750470727682114,\n",
       " 0.0014186478219926357,\n",
       " -0.03910539671778679,\n",
       " 0.008261192589998245,\n",
       " -0.09175863116979599,\n",
       " -0.0859714224934578,\n",
       " -0.06499801576137543,\n",
       " -0.003132864600047469,\n",
       " -0.016228746622800827,\n",
       " -0.04592938721179962,\n",
       " 0.050823505967855453,\n",
       " 0.015416939742863178,\n",
       " -0.012856128625571728,\n",
       " 0.018925271928310394,\n",
       " -0.07701174169778824,\n",
       " -0.02418937347829342,\n",
       " -0.03761092945933342,\n",
       " 0.02486550621688366,\n",
       " 0.02723429724574089,\n",
       " -0.04135053604841232,\n",
       " -0.030224807560443878,\n",
       " 0.07656744867563248,\n",
       " -0.06418317556381226,\n",
       " 0.006987567059695721,\n",
       " -0.0030296286568045616,\n",
       " 0.029650356620550156,\n",
       " 0.0021552129182964563,\n",
       " 0.034701015800237656,\n",
       " 0.002177407732233405,\n",
       " -0.13161417841911316,\n",
       " -0.002881936728954315,\n",
       " 0.008640444837510586,\n",
       " -0.027383271604776382,\n",
       " 0.015394129790365696,\n",
       " 0.03872270509600639,\n",
       " 0.06681133061647415,\n",
       " 0.03853287920355797,\n",
       " -0.0753965675830841,\n",
       " 0.00554132554680109,\n",
       " -0.04576612636446953,\n",
       " 0.03852330520749092,\n",
       " 0.07711651176214218,\n",
       " -0.08194345980882645,\n",
       " -0.04760733246803284,\n",
       " -0.02555440180003643,\n",
       " 0.03370661288499832,\n",
       " -0.006898249499499798,\n",
       " 2.0233236921146933e-33,\n",
       " -0.010319791734218597,\n",
       " -0.08843179047107697,\n",
       " -0.043478988111019135,\n",
       " -0.000545622140634805,\n",
       " -0.04100125655531883,\n",
       " -0.04953679069876671,\n",
       " 0.0363665372133255,\n",
       " 0.10797472298145294,\n",
       " 0.002087765373289585,\n",
       " -0.03535456210374832,\n",
       " 0.004965434782207012,\n",
       " -0.016651147976517677,\n",
       " 0.008056199178099632,\n",
       " 0.060695830732584,\n",
       " -0.04073097184300423,\n",
       " 0.027664976194500923,\n",
       " -0.05600471794605255,\n",
       " -0.041225530207157135,\n",
       " 0.0035068581346422434,\n",
       " 0.04374714568257332,\n",
       " 0.008845769800245762,\n",
       " 0.06006300821900368,\n",
       " -0.0027867360040545464,\n",
       " 0.046088069677352905,\n",
       " -0.031956881284713745,\n",
       " -0.08389163762331009,\n",
       " -0.0305008701980114,\n",
       " -0.05848003551363945,\n",
       " -0.011572524905204773,\n",
       " -0.10269393026828766,\n",
       " 0.08004629611968994,\n",
       " -0.12306198477745056,\n",
       " -0.03482571616768837,\n",
       " 0.04308807849884033,\n",
       " 0.017270538955926895,\n",
       " 0.04009807109832764,\n",
       " 0.009001904167234898,\n",
       " -0.010679330676794052,\n",
       " 0.030713653191924095,\n",
       " 0.003171199467033148,\n",
       " 0.12464849650859833,\n",
       " 0.014362890273332596,\n",
       " 0.11523936688899994,\n",
       " 0.04082386568188667,\n",
       " 0.042895279824733734,\n",
       " 0.05657723546028137,\n",
       " -0.005621838849037886,\n",
       " 0.07854082435369492,\n",
       " -0.043301720172166824,\n",
       " 0.04774486646056175,\n",
       " 0.05322299525141716,\n",
       " -0.018956458196043968,\n",
       " -0.00818769633769989,\n",
       " 0.030724434182047844,\n",
       " -0.0706729143857956,\n",
       " -0.00036347046261653304,\n",
       " 0.03445242717862129,\n",
       " -0.04046808183193207,\n",
       " 0.04871316999197006,\n",
       " 0.017976637929677963,\n",
       " 0.06460367888212204,\n",
       " -0.038938701152801514,\n",
       " -0.029212895780801773,\n",
       " -0.024484077468514442,\n",
       " 0.012541527859866619,\n",
       " -0.01843424327671528,\n",
       " -0.0259456355124712,\n",
       " -0.03229019045829773,\n",
       " -0.07023654878139496,\n",
       " 0.07101189345121384,\n",
       " -0.051520612090826035,\n",
       " -0.08857957273721695,\n",
       " -0.016587024554610252,\n",
       " -0.045670900493860245,\n",
       " 0.002960090758278966,\n",
       " 0.006937122903764248,\n",
       " -0.01536826603114605,\n",
       " -0.023982927203178406,\n",
       " -0.045482490211725235,\n",
       " -0.0456087589263916,\n",
       " 0.01846875250339508,\n",
       " 0.10922308266162872,\n",
       " 0.04048079997301102,\n",
       " -0.047475337982177734,\n",
       " 0.05199326574802399,\n",
       " 0.08675114065408707,\n",
       " 0.02615257166326046,\n",
       " -0.0210692398250103,\n",
       " 0.023424409329891205,\n",
       " 0.019121497869491577,\n",
       " -0.02205926924943924,\n",
       " 0.04253246262669563,\n",
       " -0.10057364404201508,\n",
       " 0.044329285621643066,\n",
       " -0.05095798894762993,\n",
       " -1.4237023115981629e-08,\n",
       " 0.009052949957549572,\n",
       " 0.0016542664961889386,\n",
       " 0.028532270342111588,\n",
       " -0.06800147891044617,\n",
       " 0.01881607249379158,\n",
       " -0.047881148755550385,\n",
       " 0.02869901806116104,\n",
       " 0.027604317292571068,\n",
       " 0.07552435994148254,\n",
       " -0.019900081679224968,\n",
       " 0.04741523414850235,\n",
       " -0.0371507927775383,\n",
       " -0.0920269563794136,\n",
       " 0.06363869458436966,\n",
       " 0.15495401620864868,\n",
       " 0.03230557590723038,\n",
       " -0.00830705463886261,\n",
       " 0.06530765444040298,\n",
       " 0.009236646816134453,\n",
       " -0.0694984719157219,\n",
       " 0.00971922092139721,\n",
       " 0.07340703159570694,\n",
       " 0.0014578491682186723,\n",
       " -0.006975803058594465,\n",
       " 0.021121369674801826,\n",
       " 0.02757769636809826,\n",
       " 0.009364943951368332,\n",
       " 0.028882402926683426,\n",
       " 0.052139777690172195,\n",
       " 0.02025940828025341,\n",
       " 0.060069646686315536,\n",
       " 0.006304767448455095,\n",
       " 0.059501782059669495,\n",
       " -0.05328793078660965,\n",
       " -0.07004136592149734,\n",
       " 0.011655369773507118,\n",
       " -0.05785578861832619,\n",
       " -0.0195749644190073,\n",
       " 0.09026797860860825,\n",
       " -0.04104243591427803,\n",
       " 0.05064990371465683,\n",
       " 0.011240419000387192,\n",
       " -0.03571688383817673,\n",
       " 0.02164040133357048,\n",
       " 0.020226217806339264,\n",
       " -0.009053920395672321,\n",
       " 0.00983671098947525,\n",
       " -0.08194223791360855,\n",
       " -0.023232586681842804,\n",
       " 0.009077135473489761,\n",
       " -0.04845903813838959,\n",
       " -0.0018803257262334228,\n",
       " 0.06598103046417236,\n",
       " -0.004634959157556295,\n",
       " 0.11962634325027466,\n",
       " 0.03460756316781044,\n",
       " 0.03916815668344498,\n",
       " -0.027080096304416656,\n",
       " 0.05754322558641434,\n",
       " -0.01755005121231079,\n",
       " 0.08790457993745804,\n",
       " -0.07225359976291656,\n",
       " 0.03872595354914665,\n",
       " 0.05272003263235092]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b6797c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_embeddings = user_prompt_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "929b2c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRECT (New way with 2 args)\n",
    "# Note: We use 'local_embedding_model' instead of 'embedding_client' and 'model_name'\n",
    "data_embeddings = [get_embedding(local_embedding_model, x) for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "74c1c911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity calculation successful!\n",
      "Scores shape: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 1. Make sure your 'data' variable is a LIST of strings (not just one string)\n",
    "# If 'data' is currently just one big string, this loop won't work right.\n",
    "# Assuming 'data' is like: data = [\"Menu Item 1...\", \"Menu Item 2...\", \"Policies...\"]\n",
    "\n",
    "# 2. Regenerate the embeddings correctly (This creates a List of Lists)\n",
    "data_embeddings = [get_embedding(local_embedding_model, x) for x in data]\n",
    "\n",
    "# 3. Regenerate the user prompt embedding\n",
    "user_prompt_embeddings = get_embedding(local_embedding_model, user_prompt)\n",
    "\n",
    "# 4. Run the similarity check again\n",
    "# Note: We wrap 'user_prompt_embeddings' in [] to make it 2D (1 row)\n",
    "# 'data_embeddings' is already 2D (multiple rows)\n",
    "data_similarity_scores = cosine_similarity([user_prompt_embeddings], data_embeddings)\n",
    "\n",
    "print(\"Similarity calculation successful!\")\n",
    "print(f\"Scores shape: {data_similarity_scores.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ee652d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64775942, 0.40167337]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e06a7cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_entry_index=data_similarity_scores.argmax()\n",
    "closest_entry_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5247a12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe iPhone 16 introduces several exciting updates, making it one of Apple\\'s most advanced smartphones to date. It features a larger 6.1-inch display for the base model and a 6.7-inch screen for the iPhone 16 Plus, with thinner bezels and a more durable Ceramic Shield. The iPhone 16 Pro and Pro Max boast even larger displays, measuring 6.3 and 6.9 inches respectively, offering the thinnest bezels seen on any Apple product so far.\\n\\nPowered by the new A18 chip (A18 Pro for the Pro models), these phones deliver significant performance improvements, with enhanced neural engine capabilities, faster GPU for gaming, and machine learning tasks. The camera systems are also upgraded, with the base iPhone 16 sporting a dual-camera setup with a 48MP main sensor. The Pro models offer a 48MP Ultra Wide and 5x telephoto camera, enhanced by Apple’s \"Camera Control\" button for more flexible photography options.\\n\\nApple also introduced advanced audio features like \"Audio Mix,\" which uses machine learning to separate background sounds from speech, allowing for more refined audio capture during video recording. Battery life has been extended, especially in the iPhone 16 Pro Max, which is claimed to have the longest-lasting battery of any iPhone \\n9TO5MAC\\n\\nAPPLEMAGAZINE\\n.\\n\\nAdditionally, Apple has switched to USB-C for faster charging and data transfer, and the Pro models now support up to 2x faster video encoding. The starting prices remain consistent with previous generations, with the iPhone 16 starting at $799, while the Pro models start at $999\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[closest_entry_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3e1943cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_with_data = f\"\"\"\n",
    "{data[closest_entry_index]}\n",
    "\n",
    "{user_prompt}\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "78d7473c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe iPhone 16 introduces several exciting updates, making it one of Apple\\'s most advanced smartphones to date. It features a larger 6.1-inch display for the base model and a 6.7-inch screen for the iPhone 16 Plus, with thinner bezels and a more durable Ceramic Shield. The iPhone 16 Pro and Pro Max boast even larger displays, measuring 6.3 and 6.9 inches respectively, offering the thinnest bezels seen on any Apple product so far.\\n\\nPowered by the new A18 chip (A18 Pro for the Pro models), these phones deliver significant performance improvements, with enhanced neural engine capabilities, faster GPU for gaming, and machine learning tasks. The camera systems are also upgraded, with the base iPhone 16 sporting a dual-camera setup with a 48MP main sensor. The Pro models offer a 48MP Ultra Wide and 5x telephoto camera, enhanced by Apple’s \"Camera Control\" button for more flexible photography options.\\n\\nApple also introduced advanced audio features like \"Audio Mix,\" which uses machine learning to separate background sounds from speech, allowing for more refined audio capture during video recording. Battery life has been extended, especially in the iPhone 16 Pro Max, which is claimed to have the longest-lasting battery of any iPhone \\n9TO5MAC\\n\\nAPPLEMAGAZINE\\n.\\n\\nAdditionally, Apple has switched to USB-C for faster charging and data transfer, and the Pro models now support up to 2x faster video encoding. The starting prices remain consistent with previous generations, with the iPhone 16 starting at $799, while the Pro models start at $999\\n\\n\\nWhat are the new features of the iPhone 16?\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt_with_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "969633a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new features of the iPhone 16 include:\n",
      "\n",
      "1. Larger displays:\n",
      "   - Base model: 6.1-inch display\n",
      "   - iPhone 16 Plus: 6.7-inch display\n",
      "   - iPhone 16 Pro: 6.3-inch display\n",
      "   - iPhone 16 Pro Max: 6.9-inch display\n",
      "\n",
      "2. Thinner bezels and a more durable Ceramic Shield\n",
      "\n",
      "3. Powered by the new A18 chip (A18 Pro for the Pro models), offering:\n",
      "   - Enhanced neural engine capabilities\n",
      "   - Faster GPU for gaming\n",
      "   - Machine learning tasks\n",
      "\n",
      "4. Upgraded camera systems:\n",
      "   - Base iPhone 16: Dual-camera setup with a 48MP main sensor\n",
      "   - Pro models: 48MP Ultra Wide and 5x telephoto camera\n",
      "   - Enhanced by Apple’s \"Camera Control\" button for more flexible photography options\n",
      "\n",
      "5. Advanced audio features:\n",
      "   - \"Audio Mix,\" which uses machine learning to separate background sounds from speech\n",
      "\n",
      "6. Extended battery life, especially in the iPhone 16 Pro Max, which is claimed to have the longest-lasting battery of any iPhone\n",
      "\n",
      "7. Switch to USB-C for faster charging and data transfer\n",
      "\n",
      "8. Pro models now support up to 2x faster video encoding\n",
      "\n",
      "9. Starting prices remain consistent with previous generations:\n",
      "   - iPhone 16: Starting at $799\n",
      "   - Pro models: Starting at $999\n"
     ]
    }
   ],
   "source": [
    "messages = [{'role':'user','content':user_prompt_with_data}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
